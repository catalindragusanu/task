# Ollama Configuration
# URL where Ollama is running (default: http://localhost:11434)
OLLAMA_URL=http://localhost:11434

# Ollama model to use for AI features (default: llama3.2:latest)
OLLAMA_MODEL=llama3.2:latest
OLLAMA_CONNECT_TIMEOUT=5
OLLAMA_READ_TIMEOUT=100

# Flask Configuration
# Flask environment: development or production
FLASK_ENV=development

# Enable Flask debug mode (True for development, False for production).
# In production, DEBUG should remain False.
FLASK_DEBUG=False

# Port for the backend API server
# Default: 4001 (avoids conflicts with macOS AirPlay on 5000)
PORT=4001

# CORS allowed origins (comma-separated)
# Must match the frontend URL(s)
CORS_ORIGINS=http://localhost:4000,http://localhost:4002

# Optional API key (set to enforce auth on /api routes)
API_KEY=

# Rate limits (default values shown)
DEFAULT_RATE_LIMIT=60/minute
AI_ROUTE_RATE_LIMIT=20/hour

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
